{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# using MTCNN for face detection and alignment\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# using dlib for face detection and alignment\n",
    "from eye_alignment_multiple import align_faces\t\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MTCNN for face detection and alignment (not recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if use MTCNN for face detection and alignment\n",
    "face_detector = MTCNN()\n",
    "print(\"Face detector model loded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store images and labels\n",
    "dataset_images = []\n",
    "dataset_labels = []\n",
    "label_map = {}  # Mapping of labels to indices\n",
    "label_index = 0\n",
    "\n",
    "def MTCNN_add_image(image_path):\n",
    "    \"\"\"Loads images and extracts embeddings for training.\"\"\"\n",
    "    global label_index\n",
    "\n",
    "    root, _ = os.path.splitext(image_path)\n",
    "    label = os.path.split(root)[-1]\n",
    "    match = re.search(r\"^(\\w+)_\", label)\n",
    "    label = match.group(1)\n",
    "\n",
    "    if label not in label_map:\n",
    "        label_map[label] = label_index\n",
    "        label_index += 1\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    faces = face_detector.detect_faces(image) # use MTCNN for face detection and alignment\n",
    "\n",
    "    if not faces:\n",
    "        print(f\"No face found in `{label}`, skipping.\")\n",
    "        return\n",
    "\n",
    "    if len(faces) > 1:\n",
    "        print(f\"Multiple faces found in `{label}`, skipping.\")\n",
    "        return\n",
    "    x, y, w, h = faces[0][\"box\"]\n",
    "    x1, y1 = max(0, x), max(0, y)\n",
    "    x2, y2 = min(image.shape[1], x + w), min(image.shape[0], y + h)\n",
    "\n",
    "    cropped_face = image[y1:y2, x1:x2]\n",
    "    resized_face = cv2.resize(cropped_face, (224, 224))\n",
    "    resized_face = resized_face.reshape(1, 224, 224, 3)\n",
    "\n",
    "    dataset_images.append(resized_face)\n",
    "    dataset_labels.append(label_map[label])\n",
    "\n",
    "# Load images from dataset\n",
    "for dir, _, files in os.walk(\"../Member Photos\"):\n",
    "    for file in files:\n",
    "        MTCNN_add_image(os.path.join(dir, file))\n",
    "\n",
    "dataset_images = np.array(dataset_images)\n",
    "dataset_labels = np.array(dataset_labels)\n",
    "dataset_labels = to_categorical(dataset_labels, num_classes=len(label_map))\n",
    "\n",
    "print(f\"Loaded {len(dataset_images)} images for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use dlib for face detection and alignment (faster than MTCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected!\n",
      "No face found in `aaryan`, skipping.\n",
      "No face detected!\n",
      "No face found in `aaryan`, skipping.\n",
      "No face detected!\n",
      "No face found in `ethan`, skipping.\n",
      "No face detected!\n",
      "No face found in `ethan`, skipping.\n",
      "No face detected!\n",
      "No face found in `ethan`, skipping.\n",
      "No face detected!\n",
      "No face found in `ethan`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "Loaded 83 images for training.\n"
     ]
    }
   ],
   "source": [
    "# Lists to store images and labels\n",
    "dataset_images = []\n",
    "dataset_labels = []\n",
    "label_map = {}  # Mapping of labels to indices\n",
    "label_index = 0\n",
    "\n",
    "def dlib_add_image(image_path):\n",
    "    \"\"\"Loads images and extracts embeddings for training.\"\"\"\n",
    "    global label_index\n",
    "\n",
    "    root, _ = os.path.splitext(image_path)\n",
    "    label = os.path.split(root)[-1]\n",
    "    match = re.search(r\"^(\\w+)_\", label)\n",
    "    label = match.group(1)\n",
    "\n",
    "    if label not in label_map:\n",
    "        label_map[label] = label_index\n",
    "        label_index += 1\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    faces, bounding_boxes = align_faces(image)  # use dlib for face detection and alignment\n",
    "\n",
    "    if not faces:\n",
    "        print(f\"No face found in `{label}`, skipping.\")\n",
    "        return\n",
    "\n",
    "    if len(faces) > 1:\n",
    "        print(f\"Multiple faces found in `{label}`, skipping.\")\n",
    "        return\n",
    "\n",
    "    resized_face = cv2.resize(faces[0], (224, 224))\n",
    "\n",
    "    dataset_images.append(resized_face)\n",
    "    dataset_labels.append(label_map[label])\n",
    "\n",
    "# Load images from dataset\n",
    "for dir, _, files in os.walk(\"../Member Photos\"):\n",
    "    for file in files:\n",
    "        dlib_add_image(os.path.join(dir, file))\n",
    "\n",
    "dataset_images = np.array(dataset_images)\n",
    "dataset_labels = np.array(dataset_labels)\n",
    "dataset_labels = to_categorical(dataset_labels, num_classes=len(label_map))\n",
    "\n",
    "print(f\"Loaded {len(dataset_images)} images for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset_images: (83, 224, 224, 3)\n",
      "shape of dataset_labels: (83, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of dataset_images:\", dataset_images.shape)\n",
    "print(\"shape of dataset_labels:\", dataset_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    dataset_images, dataset_labels, test_size=0.2, stratify=dataset_labels, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and fit ResNet50 for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = r\"C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/EE4228_Assignment_2/\"\n",
    "checkpoint_path = BASE + \"checkpoints/resnet50_face_recognition.h5\"\n",
    "\n",
    "# Create a callback that saves the model's weights during training\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,  # Save only the best model based on validation loss\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Custom callback to compute precision, recall, and F1-score after each epoch\n",
    "class MetricsCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(val_images), axis=1)  # Get predicted class labels\n",
    "        y_true = np.argmax(val_labels, axis=1)  # Convert one-hot labels to class indices\n",
    "\n",
    "        precision = precision_score(y_true, y_pred, average='macro')\n",
    "        recall = recall_score(y_true, y_pred, average='macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1} - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Load the pre-trained ResNet50 model without the top classification layer\n",
    "base_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(dataset_labels[1])\n",
    "\n",
    "# Add custom layers for classification\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 4.1328\n",
      "Epoch 1: val_loss improved from inf to 0.06422, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "\n",
      "Epoch 1 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 30s 5s/step - loss: 4.1328 - val_loss: 0.0642\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3054\n",
      "Epoch 2: val_loss improved from 0.06422 to 0.01037, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "1/1 [==============================] - 1s 557ms/step\n",
      "\n",
      "Epoch 2 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.3054 - val_loss: 0.0104\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1866\n",
      "Epoch 3: val_loss improved from 0.01037 to 0.00865, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "1/1 [==============================] - 1s 515ms/step\n",
      "\n",
      "Epoch 3 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.1866 - val_loss: 0.0086\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1061\n",
      "Epoch 4: val_loss improved from 0.00865 to 0.00428, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "1/1 [==============================] - 1s 551ms/step\n",
      "\n",
      "Epoch 4 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.1061 - val_loss: 0.0043\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1131\n",
      "Epoch 5: val_loss improved from 0.00428 to 0.00295, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "1/1 [==============================] - 1s 523ms/step\n",
      "\n",
      "Epoch 5 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.1131 - val_loss: 0.0030\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0827\n",
      "Epoch 6: val_loss did not improve from 0.00295\n",
      "1/1 [==============================] - 1s 555ms/step\n",
      "\n",
      "Epoch 6 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.0827 - val_loss: 0.0031\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0969\n",
      "Epoch 7: val_loss did not improve from 0.00295\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "\n",
      "Epoch 7 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.0969 - val_loss: 0.0082\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3461\n",
      "Epoch 8: val_loss did not improve from 0.00295\n",
      "1/1 [==============================] - 1s 530ms/step\n",
      "\n",
      "Epoch 8 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.3461 - val_loss: 0.0197\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1611\n",
      "Epoch 9: val_loss improved from 0.00295 to 0.00038, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "1/1 [==============================] - 1s 548ms/step\n",
      "\n",
      "Epoch 9 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.1611 - val_loss: 3.7672e-04\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0903\n",
      "Epoch 10: val_loss improved from 0.00038 to 0.00032, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "1/1 [==============================] - 1s 574ms/step\n",
      "\n",
      "Epoch 10 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.0903 - val_loss: 3.2056e-04\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0738\n",
      "Epoch 11: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 1s 510ms/step\n",
      "\n",
      "Epoch 11 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.0738 - val_loss: 0.0435\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1284\n",
      "Epoch 12: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 1s 535ms/step\n",
      "\n",
      "Epoch 12 - Precision: 0.9444, Recall: 0.9444, F1-score: 0.9333, Accuracy: 0.9412\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.1284 - val_loss: 0.0645\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0463\n",
      "Epoch 13: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "\n",
      "Epoch 13 - Precision: 0.9444, Recall: 0.9444, F1-score: 0.9333, Accuracy: 0.9412\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.0463 - val_loss: 0.2464\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.2220\n",
      "Epoch 14: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 1s 502ms/step\n",
      "\n",
      "Epoch 14 - Precision: 0.9000, Recall: 0.8056, F1-score: 0.8063, Accuracy: 0.8235\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.2220 - val_loss: 0.5755\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3102\n",
      "Epoch 15: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 1s 557ms/step\n",
      "\n",
      "Epoch 15 - Precision: 0.9000, Recall: 0.8056, F1-score: 0.8063, Accuracy: 0.8235\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.3102 - val_loss: 0.8101\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3400\n",
      "Epoch 16: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "\n",
      "Epoch 16 - Precision: 0.9444, Recall: 0.9167, F1-score: 0.9111, Accuracy: 0.9412\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.3400 - val_loss: 0.0637\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1561\n",
      "Epoch 17: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 0s 452ms/step\n",
      "\n",
      "Epoch 17 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.1561 - val_loss: 0.0131\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0581\n",
      "Epoch 18: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 0s 460ms/step\n",
      "\n",
      "Epoch 18 - Precision: 0.6944, Recall: 0.7778, F1-score: 0.7190, Accuracy: 0.8235\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.0581 - val_loss: 1.2485\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\one-shot-face-reg\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - ETA: 0s - loss: 0.4024\n",
      "Epoch 19: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "\n",
      "Epoch 19 - Precision: 0.7361, Recall: 0.7917, F1-score: 0.7524, Accuracy: 0.8235\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.4024 - val_loss: 1.5467\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1525\n",
      "Epoch 20: val_loss did not improve from 0.00032\n",
      "1/1 [==============================] - 0s 498ms/step\n",
      "\n",
      "Epoch 20 - Precision: 0.7361, Recall: 0.7917, F1-score: 0.7524, Accuracy: 0.8235\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.1525 - val_loss: 0.7875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c01c674f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, train_labels,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[checkpoint_callback, MetricsCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to iterate through test images and make predictions\n",
    "def predict_test_images(test_dir, model):\n",
    "    # Get all image paths in test directory\n",
    "    image_paths = [os.path.join(test_dir, f) for f in os.listdir(test_dir) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        # Load and preprocess image\n",
    "        image = cv2.imread(img_path)\n",
    "        faces, bounding_boxes = align_faces(image)  # use dlib for face detection and alignment\n",
    "\n",
    "        if not faces:\n",
    "            print(f\"No face found, hence skipping.\")\n",
    "            return\n",
    "\n",
    "        if len(faces) > 1:\n",
    "            print(f\"Multiple faces found, hence skipping.\")\n",
    "            return\n",
    "\n",
    "        resized_face = cv2.resize(faces[0], (224, 224))\n",
    "        resized_face = np.expand_dims(resized_face, axis=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        pred = model.predict(resized_face)\n",
    "        pred_class = np.argmax(pred, axis=1)[0]  # Get the predicted class index\n",
    "        confidence = np.max(pred)  # Get the confidence score\n",
    "        \n",
    "        predictions.append({\n",
    "            'image_path': img_path,\n",
    "            'predicted_class': pred_class,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "        \n",
    "        print(f\"Image: {os.path.basename(img_path)}\")\n",
    "        print(f\"Predicted class: {pred_class}\")\n",
    "        print(f\"Confidence: {confidence:.4f}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from `C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints/resnet50_face_recognition.h5`...\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = BASE + \"checkpoints/resnet50_face_recognition.h5\"\n",
    "\n",
    "base_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "\tprint(f\"Loading checkpoint from `{checkpoint_path}`...\")\n",
    "\t# Add custom layers again for classification\n",
    "\tx = Flatten()(base_model.output)\n",
    "\tx = Dense(128, activation='relu')(x)\n",
    "\tx = Dropout(0.5)(x)\n",
    "\tpredictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "\t# Define the new model\n",
    "\tmodel = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\t# Load the weights from the checkpoint file\n",
    "\tmodel.load_weights(checkpoint_path)\n",
    "else:\n",
    "\tprint(f\"Checkpoint `{checkpoint_path}` not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on extra test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 455ms/step\n",
      "Image: 20250320_141710.jpg\n",
      "Predicted class: 0\n",
      "Confidence: 1.0000\n",
      "---\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Image: 20250320_141825.jpg\n",
      "Predicted class: 5\n",
      "Confidence: 0.9995\n",
      "---\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Image: 20250320_141904.jpg\n",
      "Predicted class: 2\n",
      "Confidence: 1.0000\n",
      "---\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Image: 20250320_142015.jpg\n",
      "Predicted class: 4\n",
      "Confidence: 0.9994\n",
      "---\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Image: 20250320_142048.jpg\n",
      "Predicted class: 1\n",
      "Confidence: 0.9915\n",
      "---\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Image: jinwei_04.jpg\n",
      "Predicted class: 3\n",
      "Confidence: 1.0000\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# directory containing test images\n",
    "test_dir = os.path.join(BASE, \"test/\")\n",
    "\n",
    "# predict test images\n",
    "finetune_predictions = predict_test_images(test_dir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aaryan': 0, 'ethan': 1, 'eunice': 2, 'jinwei': 3, 'jonathan': 4, 'junyong': 5}\n"
     ]
    }
   ],
   "source": [
    "# corresponding labels for the test images\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Finetuned Model - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_pred_finetune = np.argmax(model.predict(val_images), axis=1)\n",
    "y_true = np.argmax(val_labels, axis=1)\n",
    "\n",
    "# Calculate metrics for the pretrained model\n",
    "precision_finetune = precision_score(y_true, y_pred_finetune, average='macro')\n",
    "recall_finetune = recall_score(y_true, y_pred_finetune, average='macro')\n",
    "f1_finetune = f1_score(y_true, y_pred_finetune, average='macro')\n",
    "accuracy_finetune = accuracy_score(y_true, y_pred_finetune)\n",
    "\n",
    "print(f\"Finetuned Model - Precision: {precision_finetune:.4f}, Recall: {recall_finetune:.4f}, F1-score: {f1_finetune:.4f}, Accuracy: {accuracy_finetune:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers again for classification\n",
    "x = Flatten()(pretrained_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the new model\n",
    "pretrained_model = Model(inputs=pretrained_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on extra test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 427ms/step\n",
      "Image: 20250320_141710.jpg\n",
      "Predicted class: 5\n",
      "Confidence: 0.5744\n",
      "---\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Image: 20250320_141825.jpg\n",
      "Predicted class: 4\n",
      "Confidence: 0.9624\n",
      "---\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Image: 20250320_141904.jpg\n",
      "Predicted class: 1\n",
      "Confidence: 0.6818\n",
      "---\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Image: 20250320_142015.jpg\n",
      "Predicted class: 4\n",
      "Confidence: 0.6332\n",
      "---\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Image: 20250320_142048.jpg\n",
      "Predicted class: 4\n",
      "Confidence: 0.5411\n",
      "---\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Image: jinwei_04.jpg\n",
      "Predicted class: 0\n",
      "Confidence: 0.3756\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test_dir = os.path.join(BASE, \"test/\")\n",
    "\n",
    "pretrained_predictions = predict_test_images(test_dir, pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 320ms/step\n",
      "Pretrained Model - Precision: 0.1389, Recall: 0.1528, F1-score: 0.1444, Accuracy: 0.1765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\one-shot-face-reg\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_pred_pretrained = np.argmax(pretrained_model.predict(val_images), axis=1)\n",
    "y_true = np.argmax(val_labels, axis=1)\n",
    "\n",
    "# Calculate metrics for the pretrained model\n",
    "precision_pretrained = precision_score(y_true, y_pred_pretrained, average='macro')\n",
    "recall_pretrained = recall_score(y_true, y_pred_pretrained, average='macro')\n",
    "f1_pretrained = f1_score(y_true, y_pred_pretrained, average='macro')\n",
    "accuracy_pretrained = accuracy_score(y_true, y_pred_pretrained)\n",
    "\n",
    "print(f\"Pretrained Model - Precision: {precision_pretrained:.4f}, Recall: {recall_pretrained:.4f}, F1-score: {f1_pretrained:.4f}, Accuracy: {accuracy_pretrained:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "one-shot-face-reg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
