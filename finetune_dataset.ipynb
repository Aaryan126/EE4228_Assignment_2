{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "# using MTCNN for face detection and alignment\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# using dlib for face detection and alignment\n",
    "from eye_alignment_multiple import align_faces\t\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MTCNN for face detection and alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detector model loded...\n"
     ]
    }
   ],
   "source": [
    "# run this if use MTCNN for face detection and alignment\n",
    "face_detector = MTCNN()\n",
    "print(\"Face detector model loded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store images and labels\n",
    "dataset_images = []\n",
    "dataset_labels = []\n",
    "label_map = {}  # Mapping of labels to indices\n",
    "label_index = 0\n",
    "\n",
    "def MTCNN_add_image(image_path):\n",
    "    \"\"\"Loads images and extracts embeddings for training.\"\"\"\n",
    "    global label_index\n",
    "\n",
    "    root, _ = os.path.splitext(image_path)\n",
    "    label = os.path.split(root)[-1]\n",
    "    match = re.search(r\"^(\\w+)_\", label)\n",
    "    label = match.group(1)\n",
    "\n",
    "    if label not in label_map:\n",
    "        label_map[label] = label_index\n",
    "        label_index += 1\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    faces = face_detector.detect_faces(image) # use MTCNN for face detection and alignment\n",
    "\n",
    "    if not faces:\n",
    "        print(f\"No face found in `{label}`, skipping.\")\n",
    "        return\n",
    "\n",
    "    if len(faces) > 1:\n",
    "        print(f\"Multiple faces found in `{label}`, skipping.\")\n",
    "        return\n",
    "    x, y, w, h = faces[0][\"box\"]\n",
    "    x1, y1 = max(0, x), max(0, y)\n",
    "    x2, y2 = min(image.shape[1], x + w), min(image.shape[0], y + h)\n",
    "\n",
    "    cropped_face = image[y1:y2, x1:x2]\n",
    "    resized_face = cv2.resize(cropped_face, (224, 224))\n",
    "    resized_face = resized_face.reshape(1, 224, 224, 3)\n",
    "\n",
    "    dataset_images.append(resized_face)\n",
    "    dataset_labels.append(label_map[label])\n",
    "\n",
    "# Load images from dataset\n",
    "for dir, _, files in os.walk(\"../Member Photos\"):\n",
    "    for file in files:\n",
    "        MTCNN_add_image(os.path.join(dir, file))\n",
    "\n",
    "dataset_images = np.array(dataset_images)\n",
    "dataset_labels = np.array(dataset_labels)\n",
    "dataset_labels = to_categorical(dataset_labels, num_classes=len(label_map))\n",
    "\n",
    "print(f\"Loaded {len(dataset_images)} images for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use dlib for face detection and alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected!\n",
      "No face found in `aaryan`, skipping.\n",
      "No face detected!\n",
      "No face found in `aaryan`, skipping.\n",
      "No face detected!\n",
      "No face found in `ethan`, skipping.\n",
      "No face detected!\n",
      "No face found in `ethan`, skipping.\n",
      "No face detected!\n",
      "No face found in `ethan`, skipping.\n",
      "No face detected!\n",
      "No face found in `ethan`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "No face detected!\n",
      "No face found in `jinwei`, skipping.\n",
      "Loaded 78 images for training.\n"
     ]
    }
   ],
   "source": [
    "# Lists to store images and labels\n",
    "dataset_images = []\n",
    "dataset_labels = []\n",
    "label_map = {}  # Mapping of labels to indices\n",
    "label_index = 0\n",
    "\n",
    "def dlib_add_image(image_path):\n",
    "    \"\"\"Loads images and extracts embeddings for training.\"\"\"\n",
    "    global label_index\n",
    "\n",
    "    root, _ = os.path.splitext(image_path)\n",
    "    label = os.path.split(root)[-1]\n",
    "    match = re.search(r\"^(\\w+)_\", label)\n",
    "    label = match.group(1)\n",
    "\n",
    "    if label not in label_map:\n",
    "        label_map[label] = label_index\n",
    "        label_index += 1\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    faces, bounding_boxes = align_faces(image)  # use dlib for face detection and alignment\n",
    "\n",
    "    if not faces:\n",
    "        print(f\"No face found in `{label}`, skipping.\")\n",
    "        return\n",
    "\n",
    "    if len(faces) > 1:\n",
    "        print(f\"Multiple faces found in `{label}`, skipping.\")\n",
    "        return\n",
    "\n",
    "    resized_face = cv2.resize(faces[0], (224, 224))\n",
    "\n",
    "    dataset_images.append(resized_face)\n",
    "    dataset_labels.append(label_map[label])\n",
    "\n",
    "# Load images from dataset\n",
    "for dir, _, files in os.walk(\"../Member Photos\"):\n",
    "    for file in files:\n",
    "        dlib_add_image(os.path.join(dir, file))\n",
    "\n",
    "dataset_images = np.array(dataset_images)\n",
    "dataset_labels = np.array(dataset_labels)\n",
    "dataset_labels = to_categorical(dataset_labels, num_classes=len(label_map))\n",
    "\n",
    "print(f\"Loaded {len(dataset_images)} images for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset_images: (78, 224, 224, 3)\n",
      "shape of dataset_labels: (78, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of dataset_images:\", dataset_images.shape)\n",
    "print(\"shape of dataset_labels:\", dataset_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet50 for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.0906 - accuracy: 0.3226 \n",
      "Epoch 1: val_loss improved from inf to 0.98544, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 16s 5s/step - loss: 3.0906 - accuracy: 0.3226 - val_loss: 0.9854 - val_accuracy: 0.6250\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.9194\n",
      "Epoch 2: val_loss improved from 0.98544 to 0.09335, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2918 - accuracy: 0.9194 - val_loss: 0.0933 - val_accuracy: 0.9375\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9355\n",
      "Epoch 3: val_loss improved from 0.09335 to 0.03791, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0942 - accuracy: 0.9355 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 4: val_loss improved from 0.03791 to 0.02950, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 5: val_loss improved from 0.02950 to 0.00422, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9677\n",
      "Epoch 6: val_loss improved from 0.00422 to 0.00093, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0488 - accuracy: 0.9677 - val_loss: 9.2588e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 7: val_loss improved from 0.00093 to 0.00023, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.2691e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 8: val_loss improved from 0.00023 to 0.00007, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 6.6035e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9677\n",
      "Epoch 9: val_loss improved from 0.00007 to 0.00002, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0623 - accuracy: 0.9677 - val_loss: 1.5474e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 10: val_loss improved from 0.00002 to 0.00000, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 4.1648e-06 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 11: val_loss improved from 0.00000 to 0.00000, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.7658e-06 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 12: val_loss improved from 0.00000 to 0.00000, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 9.0897e-07 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 13: val_loss improved from 0.00000 to 0.00000, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 6.4820e-07 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 8.3089e-04 - accuracy: 1.0000\n",
      "Epoch 14: val_loss improved from 0.00000 to 0.00000, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 8.3089e-04 - accuracy: 1.0000 - val_loss: 5.8860e-07 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 15: val_loss did not improve from 0.00000\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.1095e-07 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 16: val_loss did not improve from 0.00000\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 6.1840e-07 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 4.1154e-04 - accuracy: 1.0000\n",
      "Epoch 17: val_loss did not improve from 0.00000\n",
      "2/2 [==============================] - 7s 4s/step - loss: 4.1154e-04 - accuracy: 1.0000 - val_loss: 6.3330e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 7.6302e-04 - accuracy: 1.0000\n",
      "Epoch 18: val_loss did not improve from 0.00000\n",
      "2/2 [==============================] - 7s 4s/step - loss: 7.6302e-04 - accuracy: 1.0000 - val_loss: 6.7800e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000    \n",
      "Epoch 19: val_loss did not improve from 0.00000\n",
      "2/2 [==============================] - 7s 4s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.4075e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000    \n",
      "Epoch 20: val_loss improved from 0.00000 to 0.00000, saving model to C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints\\resnet50_face_recognition.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 5.7369e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10fa4add160>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE = r\"C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/\"\n",
    "checkpoint_path = BASE + \"checkpoints/resnet50_face_recognition.h5\"\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    dataset_images, dataset_labels, test_size=0.2, stratify=dataset_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Create a callback that saves the model's weights during training\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,  # Save only the best model based on validation loss\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load the pre-trained ResNet50 model without the top classification layer\n",
    "base_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(dataset_labels[1])\n",
    "\n",
    "# Add custom layers for classification\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_images, train_labels,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[checkpoint_callback]  # Add the callback here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_images(test_dir, model):\n",
    "    # Get all image paths in test directory\n",
    "    image_paths = [os.path.join(test_dir, f) for f in os.listdir(test_dir) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        # Load and preprocess image\n",
    "        image = cv2.imread(img_path)\n",
    "        faces, bounding_boxes = align_faces(image)  # use dlib for face detection and alignment\n",
    "\n",
    "        if not faces:\n",
    "            print(f\"No face found, hence skipping.\")\n",
    "            return\n",
    "\n",
    "        if len(faces) > 1:\n",
    "            print(f\"Multiple faces found, hence skipping.\")\n",
    "            return\n",
    "\n",
    "        resized_face = cv2.resize(faces[0], (224, 224))\n",
    "        resized_face = np.expand_dims(resized_face, axis=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        pred = model.predict(resized_face)  # Add batch dimension\n",
    "        pred_class = np.argmax(pred, axis=1)[0]  # Get the predicted class index\n",
    "        confidence = np.max(pred)  # Get the confidence score\n",
    "        \n",
    "        predictions.append({\n",
    "            'image_path': img_path,\n",
    "            'predicted_class': pred_class,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "        \n",
    "        print(f\"Image: {os.path.basename(img_path)}\")\n",
    "        print(f\"Predicted class: {pred_class}\")\n",
    "        print(f\"Confidence: {confidence:.4f}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from `C:/Users/jy158/Desktop/NTU/Notes/Y4S2/EE4228 Intelligent System Design/Assignment/real-time-one-shot-face-recognition/checkpoints/resnet50_face_recognition.h5`...\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = BASE + \"checkpoints/resnet50_face_recognition.h5\"\n",
    "base_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "\tprint(f\"Loading checkpoint from `{checkpoint_path}`...\")\n",
    "\t# Add custom layers again for classification\n",
    "\tx = Flatten()(base_model.output)\n",
    "\tx = Dense(128, activation='relu')(x)\n",
    "\tx = Dropout(0.5)(x)\n",
    "\tpredictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "\t# Define the new model (with the custom layers)\n",
    "\tmodel = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\t# Load the weights from the checkpoint file\n",
    "\tmodel.load_weights(checkpoint_path)\n",
    "else:\n",
    "\tprint(f\"Checkpoint `{checkpoint_path}` not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 484ms/step\n",
      "Image: 20250320_141825.jpg\n",
      "Predicted class: 5\n",
      "Confidence: 0.9994\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test_dir = os.path.join(BASE, \"test/\")\n",
    "\n",
    "predictions = predict_test_images(test_dir, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aaryan': 0, 'ethan': 1, 'eunice': 2, 'jinwei': 3, 'jonathan': 4, 'junyong': 5}\n"
     ]
    }
   ],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "one-shot-face-reg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
