{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e608d8a",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b293877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4b952",
   "metadata": {},
   "source": [
    "## Face detection (MTCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc5229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['aaryan', 'ethan', 'eunice', 'jinwei', 'jonathan', 'junyong']\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "####### Change as per your paths\n",
    "dataset_path = '../dataset'\n",
    "# model_path = 'Facenet/facenet_keras_2024.h5'\n",
    "output_model_path = 'baseline_cnn_embeddings.h5' \n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# Initialize MTCNN detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Get number of classes\n",
    "class_names = sorted(os.listdir(dataset_path))\n",
    "print(f\"Classes found: {class_names}\")\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Helper function to extract face from bounding box\n",
    "def get_face(img, box):\n",
    "    x1, y1, width, height = box\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # Ensure coordinates are within image bounds\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(x2, w), min(y2, h)\n",
    "    if x2 <= x1 or y2 <= y1:  # Invalid box\n",
    "        return None\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    return face\n",
    "\n",
    "# Load and preprocess data with MTCNN face detection\n",
    "def load_data():\n",
    "    X, y = [], []\n",
    "    skipped_images = 0\n",
    "    for idx, person in enumerate(class_names):\n",
    "        person_path = os.path.join(dataset_path, person)\n",
    "        for img_name in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, img_name)\n",
    "            # Load image with OpenCV\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load {img_path}, skipping.\")\n",
    "                skipped_images += 1\n",
    "                continue\n",
    "            \n",
    "            # Convert to RGB for MTCNN\n",
    "            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Detect faces\n",
    "            faces = detector.detect_faces(rgb_img)\n",
    "            if len(faces) > 0:\n",
    "                # Use the largest face (by area)\n",
    "                main_face = max(faces, key=lambda x: x['box'][2] * x['box'][3])\n",
    "                face_img = get_face(img, main_face['box'])\n",
    "                \n",
    "                if face_img is None:\n",
    "                    print(f\"Invalid face box in {img_path}, skipping.\")\n",
    "                    skipped_images += 1\n",
    "                    continue\n",
    "                \n",
    "                # Resize and preprocess\n",
    "                face_img = cv2.resize(face_img, IMG_SIZE)\n",
    "                face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "                face_array = face_img.astype('float32') / 255.0  # Normalize to [0,1]\n",
    "                \n",
    "                # Debug: Confirm detection\n",
    "                print(f\"Detected face in {img_path}: box={main_face['box']}\")\n",
    "                \n",
    "                X.append(face_array)\n",
    "                y.append(idx)\n",
    "            else:\n",
    "                print(f\"No face detected in {img_path}\")\n",
    "                skipped_images += 1\n",
    "    print(f\"Total images skipped: {skipped_images}\")\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f94c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected face in ../dataset\\aaryan\\aaryan_01.jpg: box=[200, 169, 202, 264]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_02.jpg: box=[75, 62, 60, 77]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_03.jpg: box=[562, 615, 437, 573]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_04.jpg: box=[1177, 1402, 817, 1055]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_05.jpg: box=[975, 1537, 919, 1214]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_06.jpg: box=[573, 805, 1199, 1625]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_07.jpg: box=[1043, 1685, 951, 1334]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_08.jpg: box=[1110, 1506, 897, 1175]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_09.jpg: box=[1115, 1486, 832, 1143]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_10.jpg: box=[1236, 1485, 925, 1229]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_11.jpg: box=[1375, 1446, 684, 1008]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_12.jpg: box=[628, 1186, 1045, 1357]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_13.jpg: box=[642, 1150, 1055, 1371]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_14.jpg: box=[320, 1114, 996, 1448]\n",
      "Detected face in ../dataset\\aaryan\\aaryan_15.jpg: box=[888, 1374, 565, 724]\n",
      "Detected face in ../dataset\\ethan\\ethan_01.jpg: box=[566, 860, 1538, 2012]\n",
      "Detected face in ../dataset\\ethan\\ethan_02.jpg: box=[704, 1053, 1167, 1476]\n",
      "Detected face in ../dataset\\ethan\\ethan_03.jpg: box=[726, 942, 1217, 1643]\n",
      "Detected face in ../dataset\\ethan\\ethan_04.jpg: box=[490, 835, 1205, 1508]\n",
      "Detected face in ../dataset\\ethan\\ethan_05.jpg: box=[505, 696, 1228, 1398]\n",
      "Detected face in ../dataset\\ethan\\ethan_06.jpg: box=[1128, 857, 1162, 1592]\n",
      "Detected face in ../dataset\\ethan\\ethan_07.jpg: box=[573, 1163, 1191, 1502]\n",
      "Detected face in ../dataset\\ethan\\ethan_08.jpg: box=[611, 974, 1270, 1576]\n",
      "Detected face in ../dataset\\ethan\\ethan_09.jpg: box=[687, 1256, 1152, 1494]\n",
      "Detected face in ../dataset\\ethan\\ethan_10.jpg: box=[680, 1139, 1090, 1396]\n",
      "Detected face in ../dataset\\ethan\\ethan_11.jpg: box=[593, 1306, 1236, 1454]\n",
      "Detected face in ../dataset\\ethan\\ethan_12.jpg: box=[493, 989, 1397, 1853]\n",
      "Detected face in ../dataset\\ethan\\ethan_13.jpg: box=[725, 1105, 1093, 1389]\n",
      "Detected face in ../dataset\\ethan\\ethan_14.jpg: box=[436, 981, 1369, 1803]\n",
      "Detected face in ../dataset\\ethan\\ethan_15.jpg: box=[484, 1258, 1225, 1402]\n",
      "Detected face in ../dataset\\eunice\\eunice_01.jpg: box=[640, 853, 733, 1016]\n",
      "Detected face in ../dataset\\eunice\\eunice_03.jpg: box=[459, 828, 543, 701]\n",
      "Detected face in ../dataset\\eunice\\eunice_04.jpg: box=[736, 737, 870, 1174]\n",
      "Detected face in ../dataset\\eunice\\eunice_05.jpg: box=[583, 660, 673, 896]\n",
      "Detected face in ../dataset\\eunice\\eunice_06.jpg: box=[691, 765, 751, 989]\n",
      "Detected face in ../dataset\\eunice\\eunice_07.jpg: box=[474, 676, 576, 864]\n",
      "Detected face in ../dataset\\eunice\\eunice_08.jpg: box=[320, 607, 1061, 1325]\n",
      "Detected face in ../dataset\\eunice\\eunice_09.jpg: box=[505, 713, 1159, 1679]\n",
      "Detected face in ../dataset\\eunice\\eunice_10.jpg: box=[581, 831, 1151, 1679]\n",
      "Detected face in ../dataset\\eunice\\eunice_11.jpg: box=[477, 504, 1370, 2014]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Check if data is loaded successfully\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m rgb_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Detect faces\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Use the largest face (by area)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     main_face \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(faces, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\mtcnn\\mtcnn.py:159\u001b[0m, in \u001b[0;36mMTCNN.detect_faces\u001b[1;34m(self, image, fit_to_image, limit_boundaries_landmarks, box_format, output_type, postprocess, batch_stack_justification, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Process images through each stage (PNet, RNet, ONet)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[1;32m--> 159\u001b[0m         bboxes_batch \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbboxes_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbboxes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_normalized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_oshapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages_oshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mInvalidArgumentError:  \u001b[38;5;66;03m# No faces found\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     bboxes_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m16\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\mtcnn\\stages\\stage_pnet.py:88\u001b[0m, in \u001b[0;36mStagePNet.__call__\u001b[1;34m(self, images_normalized, images_oshapes, min_face_size, min_size, scale_factor, threshold_pnet, nms_pnet1, nms_pnet2, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m scales_groups \u001b[38;5;241m=\u001b[39m [build_scale_pyramid(shape[\u001b[38;5;241m1\u001b[39m], shape[\u001b[38;5;241m0\u001b[39m], min_face_size\u001b[38;5;241m=\u001b[39mmin_face_size, scale_factor\u001b[38;5;241m=\u001b[39mscale_factor)\n\u001b[0;32m     85\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m images_oshapes]\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# 2. Apply the scales to normalized images\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m scales_result, scales_index \u001b[38;5;241m=\u001b[39m \u001b[43mapply_scales\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscales_groups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m images_normalized\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# 3. Get proposals bounding boxes and confidence from the model (PNet)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\mtcnn\\utils\\images.py:367\u001b[0m, in \u001b[0;36mapply_scales\u001b[1;34m(images_normalized, scales_groups)\u001b[0m\n\u001b[0;32m    364\u001b[0m largest_scale_group_set \u001b[38;5;241m=\u001b[39m scales_groups[selected_scaleset_as_index]\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Apply the scales from the largest scale group to the normalized images\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mscale_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlargest_scale_group_set\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, largest_scale_group_set\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\mtcnn\\utils\\images.py:367\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    364\u001b[0m largest_scale_group_set \u001b[38;5;241m=\u001b[39m scales_groups[selected_scaleset_as_index]\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Apply the scales from the largest scale group to the normalized images\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[43mscale_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m scale \u001b[38;5;129;01min\u001b[39;00m largest_scale_group_set]\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, largest_scale_group_set\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\mtcnn\\utils\\images.py:85\u001b[0m, in \u001b[0;36mscale_images\u001b[1;34m(images, scale, new_shape)\u001b[0m\n\u001b[0;32m     82\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m shape \u001b[38;5;241m*\u001b[39m scale \u001b[38;5;28;01mif\u001b[39;00m new_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m new_shape\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Resize the images using the specified scaling factor\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m images_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResizeMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAREA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images_scaled\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1790\u001b[0m, in \u001b[0;36mresize_images_v2\u001b[1;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[0;32m   1787\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1788\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResize method is not implemented: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(method))\n\u001b[1;32m-> 1790\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_resize_images_common\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresize_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_resize_if_same\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1460\u001b[0m, in \u001b[0;36m_resize_images_common\u001b[1;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Core functionality for v1 and v2 resize functions.\"\"\"\u001b[39;00m\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresize\u001b[39m\u001b[38;5;124m'\u001b[39m, [images, size]):\n\u001b[1;32m-> 1460\u001b[0m   images \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1461\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m images\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39mndims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m contains no shape.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:736\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m    735\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[1;32m--> 736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[0;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[0;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[0;32m    293\u001b[0m )\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[0;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[0;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[0;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mc:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:96\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     93\u001b[0m   \u001b[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[0;32m     95\u001b[0m   \u001b[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m   value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ops\u001b[38;5;241m.\u001b[39mEagerTensor):\n\u001b[0;32m     98\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "X, y = load_data()\n",
    "\n",
    "# Check if data is loaded successfully\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"No valid face data loaded. Check dataset or MTCNN detection.\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3f7e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 160, 160, 3) (72,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27149f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 160, 160, 3) (18,)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affffbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187be640",
   "metadata": {},
   "source": [
    "## Face recognition (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4dfa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)  # Explicit input layer\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    embeddings = layers.Dense(128, name='embeddings')(x)  # Embedding layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(embeddings)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)  # Functional model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99211153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 1.7958\n",
      "Epoch 1: val_loss improved from inf to 1.79012, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\n",
      "Epoch 1 - Precision: 0.0972, Recall: 0.2778, F1-score: 0.1407, Accuracy: 0.2778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404ms/step - loss: 1.7951 - val_loss: 1.7901\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.7872\n",
      "Epoch 2: val_loss improved from 1.79012 to 1.78426, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Epoch 2 - Precision: 0.1111, Recall: 0.3333, F1-score: 0.1667, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 1.7870 - val_loss: 1.7843\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 1.7800\n",
      "Epoch 3: val_loss improved from 1.78426 to 1.77960, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 3 - Precision: 0.1385, Recall: 0.3333, F1-score: 0.1875, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - loss: 1.7796 - val_loss: 1.7796\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 1.7635\n",
      "Epoch 4: val_loss improved from 1.77960 to 1.77321, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\n",
      "Epoch 4 - Precision: 0.1125, Recall: 0.3333, F1-score: 0.1678, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 1.7658 - val_loss: 1.7732\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.7693\n",
      "Epoch 5: val_loss improved from 1.77321 to 1.76735, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\n",
      "Epoch 5 - Precision: 0.1111, Recall: 0.3333, F1-score: 0.1667, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 1.7696 - val_loss: 1.7673\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 1.7666\n",
      "Epoch 6: val_loss improved from 1.76735 to 1.75919, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\n",
      "Epoch 6 - Precision: 0.1125, Recall: 0.3333, F1-score: 0.1678, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 1.7652 - val_loss: 1.7592\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 1.7457\n",
      "Epoch 7: val_loss did not improve from 1.75919\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\n",
      "Epoch 7 - Precision: 0.0889, Recall: 0.2222, F1-score: 0.1111, Accuracy: 0.2222\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - loss: 1.7451 - val_loss: 1.7617\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.7726\n",
      "Epoch 8: val_loss improved from 1.75919 to 1.75543, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\n",
      "Epoch 8 - Precision: 0.1190, Recall: 0.2778, F1-score: 0.1541, Accuracy: 0.2778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 1.7699 - val_loss: 1.7554\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 1.7628\n",
      "Epoch 9: val_loss improved from 1.75543 to 1.74720, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      "Epoch 9 - Precision: 0.1111, Recall: 0.3333, F1-score: 0.1667, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 1.7612 - val_loss: 1.7472\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.7303\n",
      "Epoch 10: val_loss improved from 1.74720 to 1.74157, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Epoch 10 - Precision: 0.1125, Recall: 0.3333, F1-score: 0.1678, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 1.7305 - val_loss: 1.7416\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.7360\n",
      "Epoch 11: val_loss improved from 1.74157 to 1.73563, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 11 - Precision: 0.1169, Recall: 0.3333, F1-score: 0.1714, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 1.7365 - val_loss: 1.7356\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 1.7231\n",
      "Epoch 12: val_loss improved from 1.73563 to 1.73233, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 12 - Precision: 0.1169, Recall: 0.3333, F1-score: 0.1714, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 1.7231 - val_loss: 1.7323\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 1.7405\n",
      "Epoch 13: val_loss did not improve from 1.73233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Epoch 13 - Precision: 0.1169, Recall: 0.3333, F1-score: 0.1714, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - loss: 1.7384 - val_loss: 1.7327\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 1.7221\n",
      "Epoch 14: val_loss did not improve from 1.73233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 14 - Precision: 0.1250, Recall: 0.3333, F1-score: 0.1778, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - loss: 1.7202 - val_loss: 1.7375\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.7106\n",
      "Epoch 15: val_loss improved from 1.73233 to 1.73095, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\n",
      "Epoch 15 - Precision: 0.1250, Recall: 0.3333, F1-score: 0.1778, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 1.7099 - val_loss: 1.7309\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.7327\n",
      "Epoch 16: val_loss improved from 1.73095 to 1.72314, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\n",
      "Epoch 16 - Precision: 0.1169, Recall: 0.3333, F1-score: 0.1714, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step - loss: 1.7294 - val_loss: 1.7231\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 1.7033\n",
      "Epoch 17: val_loss did not improve from 1.72314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "Epoch 17 - Precision: 0.1288, Recall: 0.3333, F1-score: 0.1825, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - loss: 1.7034 - val_loss: 1.7268\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 1.7055\n",
      "Epoch 18: val_loss did not improve from 1.72314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "Epoch 18 - Precision: 0.1250, Recall: 0.3333, F1-score: 0.1778, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - loss: 1.7058 - val_loss: 1.7262\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 1.6890\n",
      "Epoch 19: val_loss improved from 1.72314 to 1.71170, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 19 - Precision: 0.1125, Recall: 0.3333, F1-score: 0.1678, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - loss: 1.6903 - val_loss: 1.7117\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 1.7067\n",
      "Epoch 20: val_loss improved from 1.71170 to 1.71106, saving model to baseline_cnn_embeddings.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\n",
      "Epoch 20 - Precision: 0.1169, Recall: 0.3333, F1-score: 0.1714, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 1.7072 - val_loss: 1.7111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Finetuned Model - Precision: 0.1169, Recall: 0.3333, F1-score: 0.1714, Accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create CNN model\n",
    "base_model = create_model(X_train[0].shape, len(class_names))\n",
    "\n",
    "# Add classification head\n",
    "x = base_model.output\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create a callback that saves the model's weights during training\n",
    "class SaveBaseModelCallback(Callback):\n",
    "    def __init__(self, base_model, filepath, monitor='val_loss', mode='min'):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.best = np.inf if mode == 'min' else -np.inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            return\n",
    "        if ((self.mode == 'min' and current < self.best) or\n",
    "            (self.mode == 'max' and current > self.best)):\n",
    "            print(f\"\\nSaving improved base model at epoch {epoch+1}\")\n",
    "            self.best = current\n",
    "            self.base_model.save(self.filepath)\n",
    "\n",
    "# Custom callback to compute precision, recall, and F1-score after each epoch\n",
    "class MetricsCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(X_val), axis=1)  # Get predicted class labels\n",
    "        y_true = y_val\n",
    "\n",
    "        precision = precision_score(y_true, y_pred, average='macro')\n",
    "        recall = recall_score(y_true, y_pred, average='macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1} - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# create a checkpoint callback to save the model\n",
    "base_model_saver = SaveBaseModelCallback(base_model, output_model_path)\n",
    "\n",
    "# Create new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    callbacks=[base_model_saver, MetricsCallback()])\n",
    "\n",
    "# print(f\"Model fine-tuned and saved as {output_model_path}\")\n",
    "# print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "# print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_finetune = np.argmax(model.predict(X_val), axis=1)\n",
    "y_true = y_val\n",
    "\n",
    "# Calculate metrics for the pretrained model\n",
    "precision_finetune = precision_score(y_true, y_pred_finetune, average='macro')\n",
    "recall_finetune = recall_score(y_true, y_pred_finetune, average='macro')\n",
    "f1_finetune = f1_score(y_true, y_pred_finetune, average='macro')\n",
    "accuracy_finetune = accuracy_score(y_true, y_pred_finetune)\n",
    "\n",
    "print(f\"Finetuned Model - Precision: {precision_finetune:.4f}, Recall: {recall_finetune:.4f}, F1-score: {f1_finetune:.4f}, Accuracy: {accuracy_finetune:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc964a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to CNN_finetune_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save the metrics to a JSON file\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_finetune,\n",
    "    \"Recall\": recall_finetune,\n",
    "    \"F1-score\": f1_finetune,\n",
    "    \"Accuracy\": accuracy_finetune\n",
    "}\n",
    "\n",
    "# Define the file path for saving the metrics\n",
    "file_path = 'CNN_finetune_results.json'\n",
    "\n",
    "# Save the metrics to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "print(f\"Metrics saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72bc94",
   "metadata": {},
   "source": [
    "### Evaluate on pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4adc78b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step- loss: 1.793\n",
      "\n",
      "Epoch 1 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216ms/step - loss: 1.7941 - val_loss: 1.7921\n",
      "Epoch 2/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\n",
      "Epoch 2 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 1.7856 - val_loss: 1.7921\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.7991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 3 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.7991 - val_loss: 1.7921\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Epoch 4 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.7976 - val_loss: 1.7921\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.7891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\n",
      "Epoch 5 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.7892 - val_loss: 1.7921\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Epoch 6 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.7965 - val_loss: 1.7921\n",
      "Epoch 7/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\n",
      "Epoch 7 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.7895 - val_loss: 1.7921\n",
      "Epoch 8/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 8 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.7930 - val_loss: 1.7921\n",
      "Epoch 9/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Epoch 9 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 1.8014 - val_loss: 1.7921\n",
      "Epoch 10/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Epoch 10 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 1.7885 - val_loss: 1.7921\n",
      "Epoch 11/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.8042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 11 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.8039 - val_loss: 1.7921\n",
      "Epoch 12/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\n",
      "Epoch 12 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 1.7929 - val_loss: 1.7921\n",
      "Epoch 13/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\n",
      "Epoch 13 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.7939 - val_loss: 1.7921\n",
      "Epoch 14/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 14 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 1.7840 - val_loss: 1.7921\n",
      "Epoch 15/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\n",
      "Epoch 15 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.7884 - val_loss: 1.7921\n",
      "Epoch 16/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\n",
      "Epoch 16 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.7908 - val_loss: 1.7920\n",
      "Epoch 17/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.8032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Epoch 17 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.8027 - val_loss: 1.7920\n",
      "Epoch 18/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Epoch 18 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.7887 - val_loss: 1.7920\n",
      "Epoch 19/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\n",
      "Epoch 19 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.7982 - val_loss: 1.7920\n",
      "Epoch 20/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\n",
      "Epoch 20 - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.7984 - val_loss: 1.7920\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Pretrained Model - Precision: 0.0278, Recall: 0.1667, F1-score: 0.0476, Accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained FaceNet model\n",
    "base_model = create_model(X_train[0].shape, len(class_names))\n",
    "\n",
    "# freeze all layers to prevent training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add classification head\n",
    "x = base_model.output\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create new model\n",
    "model_pretrained = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile with a lower learning rate\n",
    "model_pretrained.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "history = model_pretrained.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    callbacks=[MetricsCallback()])\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_pretrained = np.argmax(model_pretrained.predict(X_val), axis=1)\n",
    "y_true = y_val\n",
    "\n",
    "# Calculate metrics for the pretrained model\n",
    "precision_pretrained = precision_score(y_true, y_pred_pretrained, average='macro')\n",
    "recall_pretrained = recall_score(y_true, y_pred_pretrained, average='macro')\n",
    "f1_pretrained = f1_score(y_true, y_pred_pretrained, average='macro')\n",
    "accuracy_pretrained = accuracy_score(y_true, y_pred_pretrained)\n",
    "\n",
    "print(f\"Pretrained Model - Precision: {precision_pretrained:.4f}, Recall: {recall_pretrained:.4f}, F1-score: {f1_pretrained:.4f}, Accuracy: {accuracy_pretrained:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74830a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to CNN_pretrained_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save the metrics to a JSON file\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_pretrained,\n",
    "    \"Recall\": recall_pretrained,\n",
    "    \"F1-score\": f1_pretrained,\n",
    "    \"Accuracy\": accuracy_pretrained\n",
    "}\n",
    "\n",
    "# Define the file path for saving the metrics\n",
    "file_path = 'CNN_pretrained_results.json'\n",
    "\n",
    "# Save the metrics to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "print(f\"Metrics saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c85d4",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c03e59a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your JSON file\n",
    "json_file_path = 'CNN_finetune_results.json'\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    metrics_data = json.load(file)\n",
    "\n",
    "print(metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2efa504f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "# cm = confusion_matrix(y_true, y_pred_finetune)\n",
    "cm = confusion_matrix(y_true, y_pred_pretrained)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5'], \n",
    "            yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa2328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
