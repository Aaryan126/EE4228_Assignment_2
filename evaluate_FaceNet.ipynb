{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec1487d2",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b293877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b1a2b",
   "metadata": {},
   "source": [
    "## Face detection (MTCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['aaryan', 'ethan', 'eunice', 'jinwei', 'jonathan', 'junyong']\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "####### Change as per your paths\n",
    "dataset_path = 'dataset'\n",
    "model_path = 'Facenet/facenet_keras_2024.h5'\n",
    "output_model_path = 'Finetuned_FaceNet/finetuned_facenet_mtcnn.keras' \n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# Initialize MTCNN detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Load the pre-trained FaceNet model\n",
    "base_model = load_model(model_path)\n",
    "\n",
    "# Unfreeze some layers for fine-tuning\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Get number of classes\n",
    "class_names = sorted(os.listdir(dataset_path))\n",
    "print(f\"Classes found: {class_names}\")\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Helper function to extract face from bounding box\n",
    "def get_face(img, box):\n",
    "    x1, y1, width, height = box\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # Ensure coordinates are within image bounds\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(x2, w), min(y2, h)\n",
    "    if x2 <= x1 or y2 <= y1:  # Invalid box\n",
    "        return None\n",
    "    face = img[y1:y2, x1:x2]\n",
    "    return face\n",
    "\n",
    "# Load and preprocess data with MTCNN face detection\n",
    "def load_data():\n",
    "    X, y = [], []\n",
    "    skipped_images = 0\n",
    "    for idx, person in enumerate(class_names):\n",
    "        person_path = os.path.join(dataset_path, person)\n",
    "        for img_name in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, img_name)\n",
    "            # Load image with OpenCV\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load {img_path}, skipping.\")\n",
    "                skipped_images += 1\n",
    "                continue\n",
    "            \n",
    "            # Convert to RGB for MTCNN\n",
    "            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Detect faces\n",
    "            faces = detector.detect_faces(rgb_img)\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                # Use the largest face (by area)\n",
    "                main_face = max(faces, key=lambda x: x['box'][2] * x['box'][3])\n",
    "                face_img = get_face(img, main_face['box'])\n",
    "                \n",
    "                if face_img is None:\n",
    "                    print(f\"Invalid face box in {img_path}, skipping.\")\n",
    "                    skipped_images += 1\n",
    "                    continue\n",
    "                \n",
    "                # Resize and preprocess\n",
    "                face_img = cv2.resize(face_img, IMG_SIZE)\n",
    "                face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "                face_array = face_img.astype('float32') / 255.0  # Normalize to [0,1]\n",
    "                \n",
    "                # Debug: Confirm detection\n",
    "                print(f\"Detected face in {img_path}: box={main_face['box']}\")\n",
    "                \n",
    "                X.append(face_array)\n",
    "                y.append(idx)\n",
    "            else:\n",
    "                print(f\"No face detected in {img_path}\")\n",
    "                skipped_images += 1\n",
    "    print(f\"Total images skipped: {skipped_images}\")\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd15f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'lambda', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (17, 17, 256), 'arguments': {'scale': 0.17}}\n",
      "{'name': 'lambda_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (17, 17, 256), 'arguments': {'scale': 0.17}}\n",
      "{'name': 'lambda_2', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (17, 17, 256), 'arguments': {'scale': 0.17}}\n",
      "{'name': 'lambda_3', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (17, 17, 256), 'arguments': {'scale': 0.17}}\n",
      "{'name': 'lambda_4', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (17, 17, 256), 'arguments': {'scale': 0.17}}\n",
      "{'name': 'lambda_5', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_6', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_7', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_8', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_9', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_10', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_11', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_12', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_13', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_14', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (8, 8, 896), 'arguments': {'scale': 0.1}}\n",
      "{'name': 'lambda_15', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (3, 3, 1792), 'arguments': {'scale': 0.2}}\n",
      "{'name': 'lambda_16', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (3, 3, 1792), 'arguments': {'scale': 0.2}}\n",
      "{'name': 'lambda_17', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (3, 3, 1792), 'arguments': {'scale': 0.2}}\n",
      "{'name': 'lambda_18', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (3, 3, 1792), 'arguments': {'scale': 0.2}}\n",
      "{'name': 'lambda_19', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (3, 3, 1792), 'arguments': {'scale': 0.2}}\n",
      "{'name': 'lambda_20', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'function': {'module': 'builtins', 'class_name': 'function', 'config': 'scaling', 'registered_name': 'function'}, 'output_shape': (3, 3, 1792), 'arguments': {'scale': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "# inspect the custom lambda layers loaded from the pretrained weight\n",
    "lambda_layer = [layer for layer in base_model.layers if isinstance(layer, layers.Lambda)]\n",
    "for layer in lambda_layer:\n",
    "    print(layer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f94c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected face in dataset\\aaryan\\aaryan_01.jpg: box=[200, 169, 202, 264]\n",
      "Detected face in dataset\\aaryan\\aaryan_02.jpg: box=[75, 62, 60, 77]\n",
      "Detected face in dataset\\aaryan\\aaryan_03.jpg: box=[562, 615, 437, 573]\n",
      "Detected face in dataset\\aaryan\\aaryan_04.jpg: box=[1177, 1402, 817, 1055]\n",
      "Detected face in dataset\\aaryan\\aaryan_05.jpg: box=[975, 1537, 919, 1214]\n",
      "Detected face in dataset\\aaryan\\aaryan_06.jpg: box=[573, 805, 1199, 1625]\n",
      "Detected face in dataset\\aaryan\\aaryan_07.jpg: box=[1043, 1685, 951, 1334]\n",
      "Detected face in dataset\\aaryan\\aaryan_08.jpg: box=[1110, 1506, 897, 1175]\n",
      "Detected face in dataset\\aaryan\\aaryan_09.jpg: box=[1115, 1486, 832, 1143]\n",
      "Detected face in dataset\\aaryan\\aaryan_10.jpg: box=[1236, 1485, 925, 1229]\n",
      "Detected face in dataset\\aaryan\\aaryan_11.jpg: box=[1375, 1446, 684, 1008]\n",
      "Detected face in dataset\\aaryan\\aaryan_12.jpg: box=[628, 1186, 1045, 1357]\n",
      "Detected face in dataset\\aaryan\\aaryan_13.jpg: box=[642, 1150, 1055, 1371]\n",
      "Detected face in dataset\\aaryan\\aaryan_14.jpg: box=[320, 1114, 996, 1448]\n",
      "Detected face in dataset\\aaryan\\aaryan_15.jpg: box=[888, 1374, 565, 724]\n",
      "Detected face in dataset\\ethan\\ethan_01.jpg: box=[566, 860, 1538, 2012]\n",
      "Detected face in dataset\\ethan\\ethan_02.jpg: box=[704, 1053, 1167, 1476]\n",
      "Detected face in dataset\\ethan\\ethan_03.jpg: box=[726, 942, 1217, 1643]\n",
      "Detected face in dataset\\ethan\\ethan_04.jpg: box=[490, 835, 1205, 1508]\n",
      "Detected face in dataset\\ethan\\ethan_05.jpg: box=[505, 696, 1228, 1398]\n",
      "Detected face in dataset\\ethan\\ethan_06.jpg: box=[1128, 857, 1162, 1592]\n",
      "Detected face in dataset\\ethan\\ethan_07.jpg: box=[573, 1163, 1191, 1502]\n",
      "Detected face in dataset\\ethan\\ethan_08.jpg: box=[611, 974, 1270, 1576]\n",
      "Detected face in dataset\\ethan\\ethan_09.jpg: box=[687, 1256, 1152, 1494]\n",
      "Detected face in dataset\\ethan\\ethan_10.jpg: box=[680, 1139, 1090, 1396]\n",
      "Detected face in dataset\\ethan\\ethan_11.jpg: box=[593, 1306, 1236, 1454]\n",
      "Detected face in dataset\\ethan\\ethan_12.jpg: box=[493, 989, 1397, 1853]\n",
      "Detected face in dataset\\ethan\\ethan_13.jpg: box=[725, 1105, 1093, 1389]\n",
      "Detected face in dataset\\ethan\\ethan_14.jpg: box=[436, 981, 1369, 1803]\n",
      "Detected face in dataset\\ethan\\ethan_15.jpg: box=[484, 1258, 1225, 1402]\n",
      "Detected face in dataset\\eunice\\eunice_01.jpg: box=[640, 853, 733, 1016]\n",
      "Detected face in dataset\\eunice\\eunice_03.jpg: box=[459, 828, 543, 701]\n",
      "Detected face in dataset\\eunice\\eunice_04.jpg: box=[736, 737, 870, 1174]\n",
      "Detected face in dataset\\eunice\\eunice_05.jpg: box=[583, 660, 673, 896]\n",
      "Detected face in dataset\\eunice\\eunice_06.jpg: box=[691, 765, 751, 989]\n",
      "Detected face in dataset\\eunice\\eunice_07.jpg: box=[474, 676, 576, 864]\n",
      "Detected face in dataset\\eunice\\eunice_08.jpg: box=[320, 607, 1061, 1325]\n",
      "Detected face in dataset\\eunice\\eunice_09.jpg: box=[505, 713, 1159, 1679]\n",
      "Detected face in dataset\\eunice\\eunice_10.jpg: box=[581, 831, 1151, 1679]\n",
      "Detected face in dataset\\eunice\\eunice_11.jpg: box=[477, 504, 1370, 2014]\n",
      "Detected face in dataset\\eunice\\eunice_12.jpg: box=[395, 509, 422, 637]\n",
      "Detected face in dataset\\eunice\\eunice_14.jpg: box=[676, 993, 498, 699]\n",
      "Detected face in dataset\\eunice\\eunice_15.jpg: box=[509, 523, 1163, 1635]\n",
      "Detected face in dataset\\eunice\\eunice_16.jpg: box=[522, 653, 977, 1302]\n",
      "Detected face in dataset\\eunice\\eunice_17.jpg: box=[970, 890, 792, 1038]\n",
      "Detected face in dataset\\jinwei\\jinwei_01.jpg: box=[1032, 1161, 1028, 1382]\n",
      "Detected face in dataset\\jinwei\\jinwei_02.jpg: box=[1150, 1353, 794, 1048]\n",
      "Detected face in dataset\\jinwei\\jinwei_03.jpg: box=[1147, 1522, 796, 1089]\n",
      "Detected face in dataset\\jinwei\\jinwei_04.jpg: box=[1069, 1535, 934, 1240]\n",
      "Detected face in dataset\\jinwei\\jinwei_05.jpg: box=[1148, 1610, 932, 1211]\n",
      "Detected face in dataset\\jinwei\\jinwei_06.jpg: box=[964, 1448, 984, 1317]\n",
      "Detected face in dataset\\jinwei\\jinwei_07.jpg: box=[1150, 1444, 850, 1078]\n",
      "Detected face in dataset\\jinwei\\jinwei_08.jpg: box=[1143, 1567, 818, 1114]\n",
      "Detected face in dataset\\jinwei\\jinwei_09.jpg: box=[761, 1381, 1484, 2053]\n",
      "Detected face in dataset\\jinwei\\jinwei_10.jpg: box=[1301, 1571, 490, 622]\n",
      "Detected face in dataset\\jinwei\\jinwei_11.jpg: box=[1195, 2007, 467, 605]\n",
      "Detected face in dataset\\jinwei\\jinwei_17.jpg: box=[807, 1095, 1053, 1265]\n",
      "Detected face in dataset\\jinwei\\jinwei_19.jpg: box=[387, 784, 973, 1126]\n",
      "Detected face in dataset\\jinwei\\jinwei_20.jpg: box=[452, 1231, 1066, 1419]\n",
      "Detected face in dataset\\jinwei\\jinwei_21.jpg: box=[572, 960, 1003, 1316]\n",
      "Detected face in dataset\\jonathan\\jonathan_01.jpg: box=[682, 991, 791, 1032]\n",
      "Detected face in dataset\\jonathan\\jonathan_02.jpg: box=[713, 1008, 799, 1075]\n",
      "Detected face in dataset\\jonathan\\jonathan_03.jpg: box=[684, 1093, 720, 959]\n",
      "Detected face in dataset\\jonathan\\jonathan_04.jpg: box=[651, 883, 739, 942]\n",
      "Detected face in dataset\\jonathan\\jonathan_05.jpg: box=[684, 1024, 729, 1001]\n",
      "Detected face in dataset\\jonathan\\jonathan_06.jpg: box=[574, 928, 1096, 1594]\n",
      "Detected face in dataset\\jonathan\\jonathan_07.jpg: box=[806, 1175, 680, 891]\n",
      "Detected face in dataset\\jonathan\\jonathan_08.jpg: box=[624, 1074, 759, 1017]\n",
      "Detected face in dataset\\jonathan\\jonathan_09.jpg: box=[633, 1111, 781, 1041]\n",
      "Detected face in dataset\\jonathan\\jonathan_10.jpg: box=[674, 1090, 746, 1010]\n",
      "Detected face in dataset\\jonathan\\jonathan_11.jpg: box=[665, 1095, 744, 985]\n",
      "Detected face in dataset\\jonathan\\jonathan_12.jpg: box=[630, 1150, 740, 979]\n",
      "Detected face in dataset\\jonathan\\jonathan_13.jpg: box=[554, 1115, 699, 997]\n",
      "Detected face in dataset\\jonathan\\jonathan_14.jpg: box=[643, 1035, 757, 1003]\n",
      "Detected face in dataset\\jonathan\\jonathan_15.jpg: box=[685, 1061, 744, 986]\n",
      "Detected face in dataset\\junyong\\junyong_01.jpg: box=[346, 386, 373, 511]\n",
      "Detected face in dataset\\junyong\\junyong_02.jpg: box=[345, 362, 362, 499]\n",
      "Detected face in dataset\\junyong\\junyong_03.jpg: box=[332, 365, 373, 518]\n",
      "Detected face in dataset\\junyong\\junyong_04.jpg: box=[430, 434, 312, 439]\n",
      "Detected face in dataset\\junyong\\junyong_05.jpg: box=[297, 403, 334, 481]\n",
      "Detected face in dataset\\junyong\\junyong_06.jpg: box=[369, 301, 382, 496]\n",
      "Detected face in dataset\\junyong\\junyong_07.jpg: box=[368, 330, 341, 482]\n",
      "Detected face in dataset\\junyong\\junyong_08.jpg: box=[324, 474, 361, 429]\n",
      "Detected face in dataset\\junyong\\junyong_09.jpg: box=[334, 277, 382, 514]\n",
      "Detected face in dataset\\junyong\\junyong_10.jpg: box=[378, 371, 275, 373]\n",
      "Detected face in dataset\\junyong\\junyong_11.jpg: box=[247, 267, 378, 517]\n",
      "Detected face in dataset\\junyong\\junyong_12.jpg: box=[293, 360, 316, 389]\n",
      "Detected face in dataset\\junyong\\junyong_13.jpg: box=[250, 238, 381, 512]\n",
      "Detected face in dataset\\junyong\\junyong_14.jpg: box=[306, 431, 327, 435]\n",
      "Detected face in dataset\\junyong\\junyong_15.jpg: box=[308, 368, 346, 461]\n",
      "Total images skipped: 0\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "X, y = load_data()\n",
    "\n",
    "# Check if data is loaded successfully\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"No valid face data loaded. Check dataset or MTCNN detection.\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d129b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 160, 160, 3) (72,)\n",
      "(18, 160, 160, 3) (18,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7ac70",
   "metadata": {},
   "source": [
    "## Face recognition (Inception Resnet V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99211153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step - loss: 2.2461\n",
      "Saving improved base model at epoch 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\n",
      "Epoch 1 - Precision: 0.1875, Recall: 0.3333, F1-score: 0.2338, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - loss: 2.2260 - val_loss: 1.4214\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - loss: 1.3221\n",
      "Saving improved base model at epoch 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "\n",
      "Epoch 2 - Precision: 0.6944, Recall: 0.6667, F1-score: 0.6468, Accuracy: 0.6667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 1.3233 - val_loss: 1.0585\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624ms/step - loss: 0.7752\n",
      "Saving improved base model at epoch 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "\n",
      "Epoch 3 - Precision: 0.8194, Recall: 0.7778, F1-score: 0.7563, Accuracy: 0.7778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.7768 - val_loss: 0.8226\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - loss: 0.4597\n",
      "Saving improved base model at epoch 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "\n",
      "Epoch 4 - Precision: 0.9167, Recall: 0.8889, F1-score: 0.8690, Accuracy: 0.8889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.4612 - val_loss: 0.6579\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - loss: 0.4501\n",
      "Saving improved base model at epoch 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "\n",
      "Epoch 5 - Precision: 0.9167, Recall: 0.8889, F1-score: 0.8690, Accuracy: 0.8889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.4512 - val_loss: 0.5383\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579ms/step - loss: 0.2748\n",
      "Saving improved base model at epoch 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\n",
      "Epoch 6 - Precision: 0.9167, Recall: 0.8889, F1-score: 0.8690, Accuracy: 0.8889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.2871 - val_loss: 0.4514\n",
      "Epoch 7/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step - loss: 0.2910\n",
      "Saving improved base model at epoch 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "\n",
      "Epoch 7 - Precision: 0.9167, Recall: 0.8889, F1-score: 0.8690, Accuracy: 0.8889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 0.2923 - val_loss: 0.3869\n",
      "Epoch 8/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - loss: 0.1874\n",
      "Saving improved base model at epoch 8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\n",
      "Epoch 8 - Precision: 0.9167, Recall: 0.8889, F1-score: 0.8690, Accuracy: 0.8889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.1887 - val_loss: 0.3409\n",
      "Epoch 9/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - loss: 0.1927\n",
      "Saving improved base model at epoch 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\n",
      "Epoch 9 - Precision: 0.9167, Recall: 0.8889, F1-score: 0.8690, Accuracy: 0.8889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.1955 - val_loss: 0.3002\n",
      "Epoch 10/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - loss: 0.1752\n",
      "Saving improved base model at epoch 10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "\n",
      "Epoch 10 - Precision: 0.9167, Recall: 0.8889, F1-score: 0.8690, Accuracy: 0.8889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.1767 - val_loss: 0.2696\n",
      "Epoch 11/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - loss: 0.1228\n",
      "Saving improved base model at epoch 11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\n",
      "Epoch 11 - Precision: 0.9167, Recall: 0.8889, F1-score: 0.8690, Accuracy: 0.8889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.1231 - val_loss: 0.2441\n",
      "Epoch 12/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - loss: 0.1152\n",
      "Saving improved base model at epoch 12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n",
      "\n",
      "Epoch 12 - Precision: 0.9583, Recall: 0.9444, F1-score: 0.9429, Accuracy: 0.9444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.1135 - val_loss: 0.2229\n",
      "Epoch 13/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - loss: 0.1387\n",
      "Saving improved base model at epoch 13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
      "\n",
      "Epoch 13 - Precision: 0.9583, Recall: 0.9444, F1-score: 0.9429, Accuracy: 0.9444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.1417 - val_loss: 0.2084\n",
      "Epoch 14/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - loss: 0.1025\n",
      "Saving improved base model at epoch 14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\n",
      "Epoch 14 - Precision: 0.9583, Recall: 0.9444, F1-score: 0.9429, Accuracy: 0.9444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.1065 - val_loss: 0.1899\n",
      "Epoch 15/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - loss: 0.0861\n",
      "Saving improved base model at epoch 15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "\n",
      "Epoch 15 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.0854 - val_loss: 0.1616\n",
      "Epoch 16/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - loss: 0.0699\n",
      "Saving improved base model at epoch 16\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\n",
      "Epoch 16 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.0712 - val_loss: 0.1404\n",
      "Epoch 17/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - loss: 0.1426\n",
      "Saving improved base model at epoch 17\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "\n",
      "Epoch 17 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.1426 - val_loss: 0.1215\n",
      "Epoch 18/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - loss: 0.1114\n",
      "Saving improved base model at epoch 18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
      "\n",
      "Epoch 18 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 0.1141 - val_loss: 0.1073\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.08\n",
      "\n",
      "Epoch 19 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753ms/step - loss: 0.0854 - val_loss: 0.1081\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.08\n",
      "\n",
      "Epoch 20 - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734ms/step - loss: 0.0868 - val_loss: 0.1132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Finetuned Model - Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Add classification head\n",
    "x = base_model.output\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create a callback that saves the model's weights during training\n",
    "class SaveBaseModelCallback(Callback):\n",
    "    def __init__(self, base_model, filepath, monitor='val_loss', mode='min'):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.best = np.inf if mode == 'min' else -np.inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            return\n",
    "        if ((self.mode == 'min' and current < self.best) or\n",
    "            (self.mode == 'max' and current > self.best)):\n",
    "            print(f\"\\nSaving improved base model at epoch {epoch+1}\")\n",
    "            self.best = current\n",
    "            self.base_model.save(self.filepath)\n",
    "\n",
    "# Custom callback to compute precision, recall, and F1-score after each epoch\n",
    "class MetricsCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(X_val), axis=1)  # Get predicted class labels\n",
    "        y_true = y_val\n",
    "\n",
    "        precision = precision_score(y_true, y_pred, average='macro')\n",
    "        recall = recall_score(y_true, y_pred, average='macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1} - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Create a checkpoint callback to save the model\n",
    "base_model_saver = SaveBaseModelCallback(base_model, output_model_path)\n",
    "\n",
    "# Create new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    callbacks=[base_model_saver, MetricsCallback()])\n",
    "\n",
    "# print(f\"Model fine-tuned and saved as {output_model_path}\")\n",
    "# print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "# print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_finetune = np.argmax(model.predict(X_val), axis=1)\n",
    "y_true = y_val\n",
    "\n",
    "# Calculate metrics for the pretrained model\n",
    "precision_finetune = precision_score(y_true, y_pred_finetune, average='macro')\n",
    "recall_finetune = recall_score(y_true, y_pred_finetune, average='macro')\n",
    "f1_finetune = f1_score(y_true, y_pred_finetune, average='macro')\n",
    "accuracy_finetune = accuracy_score(y_true, y_pred_finetune)\n",
    "\n",
    "print(f\"Finetuned Model - Precision: {precision_finetune:.4f}, Recall: {recall_finetune:.4f}, F1-score: {f1_finetune:.4f}, Accuracy: {accuracy_finetune:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a615f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to facenet_finetune_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save the metrics to a JSON file\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_finetune,\n",
    "    \"Recall\": recall_finetune,\n",
    "    \"F1-score\": f1_finetune,\n",
    "    \"Accuracy\": accuracy_finetune\n",
    "}\n",
    "\n",
    "# Define the file path for saving the metrics\n",
    "file_path = 'facenet_finetune_results.json'\n",
    "\n",
    "# Save the metrics to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "print(f\"Metrics saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72bc94",
   "metadata": {},
   "source": [
    "### Evaluate on pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4adc78b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/steptep - loss: 1.988\n",
      "\n",
      "Epoch 1 - Precision: 0.1865, Recall: 0.2778, F1-score: 0.2148, Accuracy: 0.2778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - loss: 1.9879 - val_loss: 1.6926\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 1.81\n",
      "\n",
      "Epoch 2 - Precision: 0.1865, Recall: 0.2778, F1-score: 0.2148, Accuracy: 0.2778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 1.8069 - val_loss: 1.6450\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 1.79\n",
      "\n",
      "Epoch 3 - Precision: 0.2619, Recall: 0.3333, F1-score: 0.2667, Accuracy: 0.3333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 1.8007 - val_loss: 1.5991\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.81\n",
      "\n",
      "Epoch 4 - Precision: 0.3532, Recall: 0.3889, F1-score: 0.3407, Accuracy: 0.3889\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 1.8492 - val_loss: 1.5541\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 1.70\n",
      "\n",
      "Epoch 5 - Precision: 0.3889, Recall: 0.4444, F1-score: 0.3926, Accuracy: 0.4444\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 1.7067 - val_loss: 1.5107\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 1.63\n",
      "\n",
      "Epoch 6 - Precision: 0.5667, Recall: 0.5000, F1-score: 0.4852, Accuracy: 0.5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 1.6274 - val_loss: 1.4697\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 1.62\n",
      "\n",
      "Epoch 7 - Precision: 0.5667, Recall: 0.5000, F1-score: 0.4852, Accuracy: 0.5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 1.6327 - val_loss: 1.4300\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.74\n",
      "\n",
      "Epoch 8 - Precision: 0.5667, Recall: 0.5000, F1-score: 0.4852, Accuracy: 0.5000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 1.7486 - val_loss: 1.3909\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 1.74\n",
      "\n",
      "Epoch 9 - Precision: 0.6714, Recall: 0.6667, F1-score: 0.6083, Accuracy: 0.6667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 1.7579 - val_loss: 1.3526\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 1.57\n",
      "\n",
      "Epoch 10 - Precision: 0.6714, Recall: 0.6667, F1-score: 0.6083, Accuracy: 0.6667\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 1.5818 - val_loss: 1.3151\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 1.71\n",
      "\n",
      "Epoch 11 - Precision: 0.7000, Recall: 0.7778, F1-score: 0.7167, Accuracy: 0.7778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 1.6920 - val_loss: 1.2783\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 1.63\n",
      "\n",
      "Epoch 12 - Precision: 0.7000, Recall: 0.7778, F1-score: 0.7167, Accuracy: 0.7778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 1.6274 - val_loss: 1.2431\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.31\n",
      "\n",
      "Epoch 13 - Precision: 0.7000, Recall: 0.7778, F1-score: 0.7167, Accuracy: 0.7778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 1.3336 - val_loss: 1.2096\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 1.33\n",
      "\n",
      "Epoch 14 - Precision: 0.7000, Recall: 0.7778, F1-score: 0.7167, Accuracy: 0.7778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 1.3464 - val_loss: 1.1777\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 1.64\n",
      "\n",
      "Epoch 15 - Precision: 0.7000, Recall: 0.7778, F1-score: 0.7167, Accuracy: 0.7778\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 1.6282 - val_loss: 1.1461\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 1.38\n",
      "\n",
      "Epoch 16 - Precision: 0.7250, Recall: 0.8333, F1-score: 0.7679, Accuracy: 0.8333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 1.3805 - val_loss: 1.1157\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.24\n",
      "\n",
      "Epoch 17 - Precision: 0.7250, Recall: 0.8333, F1-score: 0.7679, Accuracy: 0.8333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 1.2541 - val_loss: 1.0861\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 1.43\n",
      "\n",
      "Epoch 18 - Precision: 0.7250, Recall: 0.8333, F1-score: 0.7679, Accuracy: 0.8333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 1.4333 - val_loss: 1.0573\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 1.51\n",
      "\n",
      "Epoch 19 - Precision: 0.7250, Recall: 0.8333, F1-score: 0.7679, Accuracy: 0.8333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 1.5051 - val_loss: 1.0294\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 1.28\n",
      "\n",
      "Epoch 20 - Precision: 0.7250, Recall: 0.8333, F1-score: 0.7679, Accuracy: 0.8333\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 1.2675 - val_loss: 1.0020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "Pretrained Model - Precision: 0.7250, Recall: 0.8333, F1-score: 0.7679, Accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jy158\\miniconda3\\envs\\facenet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained FaceNet model\n",
    "base_model = load_model(model_path)\n",
    "\n",
    "# freeze all layers to prevent training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add classification head\n",
    "x = base_model.output\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create new model\n",
    "model_pretrained = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile with a lower learning rate\n",
    "model_pretrained.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "history = model_pretrained.fit(X_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    callbacks=[MetricsCallback()])\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_pretrained = np.argmax(model_pretrained.predict(X_val), axis=1)\n",
    "y_true = y_val\n",
    "\n",
    "# Calculate metrics for the pretrained model\n",
    "precision_pretrained = precision_score(y_true, y_pred_pretrained, average='macro')\n",
    "recall_pretrained = recall_score(y_true, y_pred_pretrained, average='macro')\n",
    "f1_pretrained = f1_score(y_true, y_pred_pretrained, average='macro')\n",
    "accuracy_pretrained = accuracy_score(y_true, y_pred_pretrained)\n",
    "\n",
    "print(f\"Pretrained Model - Precision: {precision_pretrained:.4f}, Recall: {recall_pretrained:.4f}, F1-score: {f1_pretrained:.4f}, Accuracy: {accuracy_pretrained:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "929948e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to facenet_pretrained_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save the metrics to a JSON file\n",
    "\n",
    "metrics = {\n",
    "    \"Precision\": precision_pretrained,\n",
    "    \"Recall\": recall_pretrained,\n",
    "    \"F1-score\": f1_pretrained,\n",
    "    \"Accuracy\": accuracy_pretrained\n",
    "}\n",
    "\n",
    "# Define the file path for saving the metrics\n",
    "file_path = 'facenet_pretrained_results.json'\n",
    "\n",
    "# Save the metrics to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(metrics, json_file, indent=4)\n",
    "\n",
    "print(f\"Metrics saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786985d4",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f133d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35142ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 1.0, 'Recall': 1.0, 'F1-score': 1.0, 'Accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your JSON file\n",
    "json_file_path = 'facenet_finetune_results.json'\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    metrics_data = json.load(file)\n",
    "\n",
    "print(metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03084379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "# cm = confusion_matrix(y_true, y_pred_finetune)\n",
    "cm = confusion_matrix(y_true, y_pred_pretrained)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5'], \n",
    "            yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c286a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
